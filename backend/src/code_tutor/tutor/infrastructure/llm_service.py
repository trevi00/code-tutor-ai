"""LLM Service for AI Tutor responses"""

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Any, Optional

from code_tutor.shared.config import get_settings
from code_tutor.shared.infrastructure.logging import get_logger

logger = get_logger(__name__)

# Lazy import for RAG engine to avoid circular imports and slow startup
_rag_engine = None


def _get_rag_engine():
    """Get RAG engine singleton with lazy loading"""
    global _rag_engine
    if _rag_engine is None:
        try:
            from code_tutor.ml import get_rag_engine
            _rag_engine = get_rag_engine()
            _rag_engine.initialize()
        except Exception as e:
            logger.warning(f"Failed to initialize RAG engine: {e}")
            _rag_engine = None
    return _rag_engine


def _get_code_analyzer():
    """Get code analyzer with lazy loading"""
    try:
        from code_tutor.ml import get_code_analyzer
        return get_code_analyzer()
    except Exception as e:
        logger.warning(f"Failed to get code analyzer: {e}")
        return None


class LLMService(ABC):
    """Abstract base class for LLM services"""

    @abstractmethod
    async def generate_response(
        self,
        user_message: str,
        context: str | None = None,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> str:
        """Generate a response to the user's message"""
        pass

    @abstractmethod
    async def analyze_code(
        self,
        code: str,
        language: str = "python",
    ) -> dict[str, Any]:
        """Analyze code and provide feedback"""
        pass


class PatternBasedLLMService(LLMService):
    """
    Pattern-based LLM service using pre-defined algorithm patterns.
    This can be upgraded to use actual LLM models later.
    """

    def __init__(self, patterns_dir: Path | None = None) -> None:
        self._patterns_dir = patterns_dir or Path("docs/patterns")
        self._patterns: dict[str, str] = {}
        self._load_patterns()

    def _load_patterns(self) -> None:
        """Load algorithm patterns from markdown files"""
        if not self._patterns_dir.exists():
            logger.warning(f"Patterns directory not found: {self._patterns_dir}")
            return

        for pattern_file in self._patterns_dir.glob("*.md"):
            try:
                content = pattern_file.read_text(encoding="utf-8")
                pattern_name = pattern_file.stem
                self._patterns[pattern_name] = content
                logger.debug(f"Loaded pattern: {pattern_name}")
            except Exception as e:
                logger.error(f"Failed to load pattern {pattern_file}: {e}")

        logger.info(f"Loaded {len(self._patterns)} algorithm patterns")

    def _find_relevant_patterns(self, query: str) -> list[tuple[str, str]]:
        """Find patterns relevant to the query"""
        query_lower = query.lower()
        relevant = []

        # Keyword mapping to patterns
        keyword_patterns = {
            "two pointer": "01_two_pointers",
            "íˆ¬ í¬ì¸í„°": "01_two_pointers",
            "sliding window": "02_sliding_window",
            "ìŠ¬ë¼ì´ë”© ìœˆë„ìš°": "02_sliding_window",
            "bfs": "07_bfs",
            "ë„ˆë¹„ ìš°ì„ ": "07_bfs",
            "dfs": "08_dfs",
            "ê¹Šì´ ìš°ì„ ": "08_dfs",
            "binary search": "09_binary_search",
            "ì´ì§„ íƒìƒ‰": "09_binary_search",
            "dp": "12_dp_01_knapsack",
            "dynamic programming": "12_dp_01_knapsack",
            "ë™ì  í”„ë¡œê·¸ëž˜ë°": "12_dp_01_knapsack",
            "ë°°ë‚­": "12_dp_01_knapsack",
            "knapsack": "12_dp_01_knapsack",
            "backtracking": "14_backtracking",
            "ë°±íŠ¸ëž˜í‚¹": "14_backtracking",
            "greedy": "15_greedy",
            "ê·¸ë¦¬ë””": "15_greedy",
            "íƒìš•": "15_greedy",
            "union find": "16_union_find",
            "ìœ ë‹ˆì˜¨ íŒŒì¸ë“œ": "16_union_find",
            "dijkstra": "17_shortest_path",
            "ë‹¤ìµìŠ¤íŠ¸ë¼": "17_shortest_path",
            "ìµœë‹¨ ê²½ë¡œ": "17_shortest_path",
            "trie": "18_trie",
            "íŠ¸ë¼ì´": "18_trie",
        }

        for keyword, pattern_name in keyword_patterns.items():
            if keyword in query_lower and pattern_name in self._patterns:
                relevant.append((pattern_name, self._patterns[pattern_name]))

        return relevant[:3]  # Return top 3 matches

    async def generate_response(
        self,
        user_message: str,
        context: str | None = None,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> str:
        """Generate a response based on algorithm patterns"""
        # Find relevant patterns
        relevant_patterns = self._find_relevant_patterns(user_message)

        if relevant_patterns:
            # Extract key information from the first matching pattern
            pattern_name, pattern_content = relevant_patterns[0]
            return self._format_pattern_response(pattern_name, pattern_content, user_message)

        # Default response when no pattern is found
        return self._generate_default_response(user_message, context)

    def _format_pattern_response(
        self,
        pattern_name: str,
        pattern_content: str,
        user_message: str,
    ) -> str:
        """Format a response using pattern content"""
        # Extract title from pattern
        lines = pattern_content.split("\n")
        title = lines[0].replace("#", "").strip() if lines else pattern_name

        # Extract key sections
        sections = {
            "ê°œìš”": "",
            "ì–¸ì œ ì‚¬ìš©": "",
            "í…œí”Œë¦¿": "",
            "ì‹œê°„ ë³µìž¡ë„": "",
        }

        current_section = ""
        for line in lines:
            if line.startswith("##"):
                section_name = line.replace("#", "").strip()
                for key in sections:
                    if key in section_name:
                        current_section = key
                        break
            elif current_section and line.strip():
                sections[current_section] += line + "\n"

        response = f"""## {title}

{sections.get('ê°œìš”', '').strip()[:500]}

### ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?
{sections.get('ì–¸ì œ ì‚¬ìš©', '').strip()[:300] or 'ì´ íŒ¨í„´ì€ íŠ¹ì • ì¡°ê±´ì—ì„œ íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.'}

ë” ìžì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! í…œí”Œë¦¿ ì½”ë“œë‚˜ ì˜ˆì œ ë¬¸ì œë„ ë³´ì—¬ë“œë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤."""

        return response

    def _generate_default_response(
        self,
        user_message: str,
        context: str | None,
    ) -> str:
        """Generate a default response when no pattern matches"""
        lower_msg = user_message.lower()

        if any(word in lower_msg for word in ["ì•ˆë…•", "hello", "hi"]):
            return """ì•ˆë…•í•˜ì„¸ìš”! ì•Œê³ ë¦¬ì¦˜ í•™ìŠµì„ ë„ì™€ë“œë¦¬ëŠ” AI íŠœí„°ìž…ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤:
- **ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì„¤ëª…**: Two Pointers, Sliding Window, DP ë“± 25ê°œ í•µì‹¬ íŒ¨í„´
- **ì½”ë“œ ë¦¬ë·°**: ë³µìž¡ë„ ë¶„ì„, ê°œì„  ì œì•ˆ
- **ë¬¸ì œ í’€ì´ ížŒíŠ¸**: ì–´ë–¤ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€

ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"""

        if any(word in lower_msg for word in ["ì‹œê°„ ë³µìž¡ë„", "big o", "ë³µìž¡ë„"]):
            return """## ì‹œê°„ ë³µìž¡ë„ ë¶„ì„

ì•Œê³ ë¦¬ì¦˜ì˜ íš¨ìœ¨ì„±ì„ ì¸¡ì •í•˜ëŠ” ë°©ë²•ìž…ë‹ˆë‹¤.

**ì¼ë°˜ì ì¸ ì‹œê°„ ë³µìž¡ë„:**
- O(1): ìƒìˆ˜ ì‹œê°„ - ë°°ì—´ ì¸ë±ì‹±
- O(log n): ë¡œê·¸ ì‹œê°„ - ì´ì§„ íƒìƒ‰
- O(n): ì„ í˜• ì‹œê°„ - ë°°ì—´ ìˆœíšŒ
- O(n log n): ë¡œê·¸ ì„ í˜• - ë³‘í•© ì •ë ¬, í€µ ì •ë ¬
- O(nÂ²): ì œê³± ì‹œê°„ - ì´ì¤‘ ë£¨í”„, ë²„ë¸” ì •ë ¬
- O(2^n): ì§€ìˆ˜ ì‹œê°„ - ë¶€ë¶„ì§‘í•© ìƒì„±

íŠ¹ì • ì•Œê³ ë¦¬ì¦˜ì˜ ë³µìž¡ë„ê°€ ê¶ê¸ˆí•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"""

        if context and "code" in lower_msg:
            return f"""ì½”ë“œë¥¼ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

{context[:200] if context else ''}

**ë¦¬ë·° í¬ì¸íŠ¸:**
1. ë³€ìˆ˜ëª…ì´ ëª…í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”
2. ì—£ì§€ ì¼€ì´ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê³  ìžˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
3. ì‹œê°„ ë³µìž¡ë„ë¥¼ ê°œì„ í•  ìˆ˜ ìžˆëŠ”ì§€ ê³ ë ¤í•´ë³´ì„¸ìš”

êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ ìžˆìœ¼ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”!"""

        return """ì¢‹ì€ ì§ˆë¬¸ìž…ë‹ˆë‹¤!

ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œë¥¼ í’€ ë•ŒëŠ” ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤:

1. **ë¬¸ì œ ì´í•´**: ìž…ë ¥ê³¼ ì¶œë ¥ì„ ëª…í™•ížˆ íŒŒì•…
2. **ì˜ˆì œ ë¶„ì„**: ì†ìœ¼ë¡œ í’€ì–´ë³´ë©° íŒ¨í„´ ë°œê²¬
3. **ì ‘ê·¼ë²• ì„ íƒ**: ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì„ íƒ
4. **êµ¬í˜„**: ì½”ë“œ ìž‘ì„±
5. **ê²€ì¦**: ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸

ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?
(ì˜ˆ: Two Pointers, DP, BFS/DFS, Binary Search ë“±)"""

    async def analyze_code(
        self,
        code: str,
        language: str = "python",
    ) -> dict[str, Any]:
        """Analyze code and provide feedback"""
        analysis = {
            "suggestions": [],
            "complexity": {"time": "O(?)", "space": "O(?)"},
            "issues": [],
            "score": 70,
        }

        lines = code.split("\n")
        num_lines = len(lines)

        # Basic analysis
        if num_lines > 50:
            analysis["suggestions"].append("í•¨ìˆ˜ë¥¼ ë” ìž‘ì€ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")

        # Check for common patterns
        if "for" in code and "for" in code[code.index("for") + 3:]:
            analysis["complexity"]["time"] = "O(nÂ²)"
            analysis["suggestions"].append("ì´ì¤‘ ë£¨í”„ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë” íš¨ìœ¨ì ì¸ ë°©ë²•ì´ ìžˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")

        if "while True" in code:
            analysis["issues"].append("ë¬´í•œ ë£¨í”„ ê°€ëŠ¥ì„±ì´ ìžˆìŠµë‹ˆë‹¤. ì¢…ë£Œ ì¡°ê±´ì„ í™•ì¸í•˜ì„¸ìš”.")

        if "pass" in code:
            analysis["issues"].append("êµ¬í˜„ë˜ì§€ ì•Šì€ ë¶€ë¶„(pass)ì´ ìžˆìŠµë‹ˆë‹¤.")

        # Score adjustment
        analysis["score"] -= len(analysis["issues"]) * 10
        analysis["score"] = max(0, min(100, analysis["score"]))

        return analysis


class RAGBasedLLMService(LLMService):
    """
    RAG-based LLM service using FAISS vector store and algorithm patterns.

    Features:
    - Semantic search using embeddings
    - 25 algorithm pattern knowledge base
    - Code analysis using CodeBERT
    - Optional LLM integration (EEVE-Korean or OpenAI)
    """

    def __init__(self) -> None:
        self._rag_engine = None
        self._code_analyzer = None

    def _ensure_rag_engine(self):
        """Ensure RAG engine is loaded"""
        if self._rag_engine is None:
            self._rag_engine = _get_rag_engine()
        return self._rag_engine

    def _ensure_code_analyzer(self):
        """Ensure code analyzer is loaded"""
        if self._code_analyzer is None:
            self._code_analyzer = _get_code_analyzer()
        return self._code_analyzer

    async def generate_response(
        self,
        user_message: str,
        context: str | None = None,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> str:
        """Generate response using RAG with algorithm patterns"""
        rag = self._ensure_rag_engine()

        if rag is None:
            # Fallback to pattern-based service
            return await self._generate_fallback_response(user_message, context)

        try:
            # Retrieve relevant patterns
            patterns = rag.retrieve(user_message, top_k=3)

            if not patterns:
                return await self._generate_fallback_response(user_message, context)

            # Check if code analysis is needed
            if context and "```" in (context or ""):
                code_analysis = await self._analyze_code_context(context)
                if code_analysis:
                    return self._format_code_analysis_response(
                        user_message, patterns, code_analysis
                    )

            # Generate response using RAG
            response = rag.generate(
                query=user_message,
                context=patterns,
                max_tokens=1024
            )

            return response

        except Exception as e:
            logger.error(f"RAG generation failed: {e}")
            return await self._generate_fallback_response(user_message, context)

    async def _analyze_code_context(self, context: str) -> Optional[dict]:
        """Analyze code in context"""
        analyzer = self._ensure_code_analyzer()
        if analyzer is None:
            return None

        # Extract code from markdown code block
        import re
        code_match = re.search(r"```(\w*)\n(.*?)```", context, re.DOTALL)
        if not code_match:
            return None

        language = code_match.group(1) or "python"
        code = code_match.group(2)

        try:
            return analyzer.analyze(code, language)
        except Exception as e:
            logger.warning(f"Code analysis failed: {e}")
            return None

    def _format_code_analysis_response(
        self,
        user_message: str,
        patterns: list,
        analysis: dict
    ) -> str:
        """Format response with code analysis"""
        response_parts = []

        # Detected patterns
        if analysis.get("patterns"):
            detected = analysis["patterns"][:2]
            pattern_names = [f"**{p['pattern_ko']}**" for p in detected]
            response_parts.append(
                f"ì½”ë“œì—ì„œ {', '.join(pattern_names)} íŒ¨í„´ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤."
            )

        # Quality score
        quality = analysis.get("quality", {})
        if quality.get("score"):
            response_parts.append(f"\n**ì½”ë“œ í’ˆì§ˆ ì ìˆ˜**: {quality['score']}/100 ({quality.get('grade', 'N/A')})")

        # Complexity
        complexity = analysis.get("complexity", {})
        if complexity:
            response_parts.append(
                f"\n**ë³µìž¡ë„**: ì‹œê°„ O({complexity.get('cyclomatic', '?')}), "
                f"ì¤‘ì²© ê¹Šì´ {complexity.get('nesting_depth', 0)}"
            )

        # Code smells
        smells = analysis.get("code_smells", [])
        if smells:
            response_parts.append("\n**ê°œì„  í•„ìš” ì‚¬í•­**:")
            for smell in smells[:3]:
                response_parts.append(f"- {smell['message']}")

        # Suggestions from patterns
        if patterns:
            main_pattern = patterns[0]
            response_parts.append(
                f"\n**ì¶”ì²œ íŒ¨í„´**: {main_pattern['name_ko']}\n"
                f"{main_pattern['description_ko']}"
            )

            if main_pattern.get("example_code"):
                response_parts.append(
                    f"\n**ì°¸ê³  ì½”ë“œ**:\n```python\n{main_pattern['example_code'][:300]}...\n```"
                )

        return "\n".join(response_parts)

    async def _generate_fallback_response(
        self,
        user_message: str,
        context: str | None = None,
    ) -> str:
        """Generate fallback response when RAG is unavailable"""
        lower_msg = user_message.lower()

        # Greeting
        if any(word in lower_msg for word in ["ì•ˆë…•", "hello", "hi", "ì²˜ìŒ"]):
            return """ì•ˆë…•í•˜ì„¸ìš”! ì•Œê³ ë¦¬ì¦˜ í•™ìŠµì„ ë„ì™€ë“œë¦¬ëŠ” AI íŠœí„°ìž…ë‹ˆë‹¤. ðŸ¤–

**ì œê°€ ë„ì™€ë“œë¦´ ìˆ˜ ìžˆëŠ” ê²ƒë“¤:**
- ðŸ“š **ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì„¤ëª…**: 25ê°œ í•µì‹¬ íŒ¨í„´ (Two Pointers, DP, BFS/DFS ë“±)
- ðŸ” **ì½”ë“œ ë¦¬ë·°**: ë³µìž¡ë„ ë¶„ì„, íŒ¨í„´ ê°ì§€, ê°œì„  ì œì•ˆ
- ðŸ’¡ **ë¬¸ì œ í’€ì´ ížŒíŠ¸**: ì í•©í•œ ì ‘ê·¼ë²• ì¶”ì²œ

ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"""

        # Algorithm-specific queries
        pattern_keywords = {
            "two pointer": "íˆ¬ í¬ì¸í„°",
            "íˆ¬ í¬ì¸í„°": "íˆ¬ í¬ì¸í„°",
            "sliding window": "ìŠ¬ë¼ì´ë”© ìœˆë„ìš°",
            "ìŠ¬ë¼ì´ë”©": "ìŠ¬ë¼ì´ë”© ìœˆë„ìš°",
            "bfs": "BFS (ë„ˆë¹„ ìš°ì„  íƒìƒ‰)",
            "ë„ˆë¹„ ìš°ì„ ": "BFS (ë„ˆë¹„ ìš°ì„  íƒìƒ‰)",
            "dfs": "DFS (ê¹Šì´ ìš°ì„  íƒìƒ‰)",
            "ê¹Šì´ ìš°ì„ ": "DFS (ê¹Šì´ ìš°ì„  íƒìƒ‰)",
            "binary search": "ì´ì§„ íƒìƒ‰",
            "ì´ì§„ íƒìƒ‰": "ì´ì§„ íƒìƒ‰",
            "dp": "ë™ì  í”„ë¡œê·¸ëž˜ë°",
            "dynamic": "ë™ì  í”„ë¡œê·¸ëž˜ë°",
            "ë™ì ": "ë™ì  í”„ë¡œê·¸ëž˜ë°",
            "greedy": "ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜",
            "ê·¸ë¦¬ë””": "ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜",
            "íƒìš•": "ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜",
            "backtrack": "ë°±íŠ¸ëž˜í‚¹",
            "ë°±íŠ¸ëž˜í‚¹": "ë°±íŠ¸ëž˜í‚¹",
        }

        for keyword, pattern_name in pattern_keywords.items():
            if keyword in lower_msg:
                return f"""## {pattern_name}

ì´ íŒ¨í„´ì— ëŒ€í•´ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**í•µì‹¬ ê°œë…:**
- íŠ¹ì • ì¡°ê±´ì—ì„œ íš¨ìœ¨ì ì¸ ë¬¸ì œ í•´ê²° ê¸°ë²•
- ì‹œê°„/ê³µê°„ ë³µìž¡ë„ ìµœì í™”ì— ìœ ìš©

ë” ìžì„¸í•œ ì„¤ëª…ì´ë‚˜ ì˜ˆì œ ì½”ë“œê°€ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!
í…œí”Œë¦¿ ì½”ë“œì™€ ì‹¤ì œ ë¬¸ì œ ì ìš© ì‚¬ë¡€ë„ ì•Œë ¤ë“œë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤."""

        # Default response
        return """ì¢‹ì€ ì§ˆë¬¸ìž…ë‹ˆë‹¤!

ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œë¥¼ í’€ ë•Œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤:

1. **ë¬¸ì œ ì´í•´**: ìž…ë ¥/ì¶œë ¥ íŒŒì•…
2. **ì˜ˆì œ ë¶„ì„**: íŒ¨í„´ ë°œê²¬
3. **ì ‘ê·¼ë²• ì„ íƒ**: ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
4. **êµ¬í˜„**: ì½”ë“œ ìž‘ì„±
5. **ê²€ì¦**: ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸

ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"""

    async def analyze_code(
        self,
        code: str,
        language: str = "python",
    ) -> dict[str, Any]:
        """Analyze code using CodeBERT-based analyzer"""
        analyzer = self._ensure_code_analyzer()

        if analyzer:
            try:
                return analyzer.analyze(code, language)
            except Exception as e:
                logger.error(f"Code analysis failed: {e}")

        # Fallback basic analysis
        return self._basic_code_analysis(code, language)

    def _basic_code_analysis(self, code: str, language: str) -> dict[str, Any]:
        """Basic code analysis fallback"""
        analysis = {
            "patterns": [],
            "quality": {"score": 70, "grade": "C"},
            "complexity": {"cyclomatic": 1, "nesting_depth": 0},
            "suggestions": [],
            "code_smells": []
        }

        lines = code.split("\n")

        # Check for nested loops
        if "for" in code and code.count("for") > 1:
            analysis["complexity"]["cyclomatic"] = 5
            analysis["suggestions"].append("ì´ì¤‘ ë£¨í”„ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë” íš¨ìœ¨ì ì¸ ë°©ë²•ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")

        # Check for common issues
        if "import *" in code:
            analysis["code_smells"].append({
                "type": "wildcard_import",
                "message": "ì™€ì¼ë“œì¹´ë“œ importëŠ” í”¼í•˜ì„¸ìš”."
            })
            analysis["quality"]["score"] -= 10

        if len(lines) > 50:
            analysis["suggestions"].append("í•¨ìˆ˜ê°€ ê¹ë‹ˆë‹¤. ë” ìž‘ì€ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”.")
            analysis["quality"]["score"] -= 5

        analysis["quality"]["grade"] = (
            "A" if analysis["quality"]["score"] >= 90 else
            "B" if analysis["quality"]["score"] >= 80 else
            "C" if analysis["quality"]["score"] >= 70 else
            "D" if analysis["quality"]["score"] >= 60 else "F"
        )

        return analysis


def get_llm_service() -> LLMService:
    """Factory function to get the appropriate LLM service"""
    settings = get_settings()

    # Try RAG-based service first
    try:
        return RAGBasedLLMService()
    except Exception as e:
        logger.warning(f"Failed to create RAG-based service: {e}")

    # Fallback to pattern-based service
    patterns_dir = Path(__file__).parent.parent.parent.parent.parent.parent / "docs" / "patterns"
    return PatternBasedLLMService(patterns_dir)
