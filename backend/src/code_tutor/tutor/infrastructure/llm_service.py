"""LLM Service for AI Tutor responses"""

from abc import ABC, abstractmethod
from enum import IntEnum
from pathlib import Path
from typing import Any
from uuid import UUID

import httpx

from code_tutor.shared.config import get_settings
from code_tutor.shared.infrastructure.logging import get_logger

logger = get_logger(__name__)


# ============== Progressive Hint System ==============

class HintLevel(IntEnum):
    """Progressive hint levels from vague to specific"""
    APPROACH = 1      # ì ‘ê·¼ë²• íŒíŠ¸ (ê°€ì¥ ì•½í•œ)
    ALGORITHM = 2     # ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì œì‹œ
    PSEUDOCODE = 3    # ì˜ì‚¬ì½”ë“œ ì œê³µ
    PARTIAL_CODE = 4  # ë¶€ë¶„ ì½”ë“œ ì œê³µ
    FULL_SOLUTION = 5 # ì „ì²´ í•´ë‹µ (ëª…ì‹œì  ìš”ì²­ ì‹œë§Œ)


class ProgressiveHintSystem:
    """
    ë‹¨ê³„ë³„ íŒíŠ¸ ì œê³µ ì‹œìŠ¤í…œ.

    ì‚¬ìš©ìì˜ ì‹œë„ íšŸìˆ˜ì™€ ìš”ì²­ì— ë”°ë¼ ì ì§„ì ìœ¼ë¡œ ë” ìƒì„¸í•œ íŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """

    # íŒíŠ¸ ë ˆë²¨ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    HINT_TEMPLATES = {
        HintLevel.APPROACH: """## ğŸ’¡ ì ‘ê·¼ ë°©í–¥ íŒíŠ¸

ì´ ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•œ ë°©í–¥ì„ ì œì‹œí•´ë“œë¦´ê²Œìš”.

**ë¬¸ì œ ìœ í˜•**: {problem_type}

**ìƒê°í•´ë³¼ ì§ˆë¬¸ë“¤**:
{guiding_questions}

**í‚¤ì›Œë“œ**: {keywords}

ìŠ¤ìŠ¤ë¡œ ì¡°ê¸ˆ ë” ìƒê°í•´ë³´ì‹œê³ , ë§‰íˆë©´ ë‹¤ìŒ íŒíŠ¸ë¥¼ ìš”ì²­í•´ì£¼ì„¸ìš”!""",

        HintLevel.ALGORITHM: """## ğŸ“š ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ íŒíŠ¸

ì´ ë¬¸ì œì— ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ì„ ì•Œë ¤ë“œë¦´ê²Œìš”.

**ì¶”ì²œ íŒ¨í„´**: {pattern_name}
**íŒ¨í„´ ì„¤ëª…**: {pattern_description}

**ì™œ ì´ íŒ¨í„´ì¸ê°€ìš”?**
{pattern_reasoning}

**ì´ íŒ¨í„´ì˜ í•µì‹¬ ì•„ì´ë””ì–´**:
{pattern_key_idea}

ì´ íŒ¨í„´ì„ ì–´ë–»ê²Œ ì ìš©í•  ìˆ˜ ìˆì„ì§€ ìƒê°í•´ë³´ì„¸ìš”!""",

        HintLevel.PSEUDOCODE: """## ğŸ“ ì˜ì‚¬ì½”ë“œ íŒíŠ¸

ì•Œê³ ë¦¬ì¦˜ì˜ ì „ì²´ íë¦„ì„ ì˜ì‚¬ì½”ë“œë¡œ ë³´ì—¬ë“œë¦´ê²Œìš”.

```
{pseudocode}
```

**ê° ë‹¨ê³„ ì„¤ëª…**:
{step_explanations}

ì´ì œ ì´ ì˜ì‚¬ì½”ë“œë¥¼ Python ì½”ë“œë¡œ ë³€í™˜í•´ë³´ì„¸ìš”!""",

        HintLevel.PARTIAL_CODE: """## ğŸ”§ ë¶€ë¶„ ì½”ë“œ íŒíŠ¸

í•µì‹¬ ë¶€ë¶„ì˜ ì½”ë“œ ê³¨ê²©ì„ ì œê³µí•´ë“œë¦´ê²Œìš”.

```python
{partial_code}
```

**ë¹ˆ ë¶€ë¶„ íŒíŠ¸**:
{fill_hints}

ë¹ˆ ë¶€ë¶„ì„ ì§ì ‘ ì±„ì›Œë³´ì„¸ìš”!""",

        HintLevel.FULL_SOLUTION: """## âœ… ì „ì²´ í’€ì´

ìµœì¢… í’€ì´ë¥¼ ë³´ì—¬ë“œë¦´ê²Œìš”. ë‹¤ìŒì—ëŠ” ìŠ¤ìŠ¤ë¡œ í’€ì–´ë³¼ ìˆ˜ ìˆë„ë¡ í•´ë³´ì„¸ìš”!

```python
{full_code}
```

**í•µì‹¬ í¬ì¸íŠ¸**:
{key_points}

**ì‹œê°„ ë³µì¡ë„**: {time_complexity}
**ê³µê°„ ë³µì¡ë„**: {space_complexity}

**í•™ìŠµ í¬ì¸íŠ¸**: ì´ ë¬¸ì œë¥¼ í†µí•´ {learning_points}ë¥¼ ë°°ì› ìŠµë‹ˆë‹¤."""
    }

    def __init__(self):
        # ì‚¬ìš©ìë³„, ë¬¸ì œë³„ íŒíŠ¸ ìƒíƒœ ì¶”ì 
        self._hint_states: dict[str, dict[str, int]] = {}  # {user_id: {problem_id: hint_level}}

    def get_current_level(self, user_id: str | UUID, problem_id: str | UUID) -> int:
        """í˜„ì¬ íŒíŠ¸ ë ˆë²¨ ì¡°íšŒ"""
        user_key = str(user_id)
        problem_key = str(problem_id)

        if user_key not in self._hint_states:
            self._hint_states[user_key] = {}

        return self._hint_states[user_key].get(problem_key, 0)

    def request_hint(
        self,
        user_id: str | UUID,
        problem_id: str | UUID,
        force_level: int | None = None
    ) -> HintLevel:
        """
        ë‹¤ìŒ ë ˆë²¨ì˜ íŒíŠ¸ ìš”ì²­.

        Args:
            user_id: ì‚¬ìš©ì ID
            problem_id: ë¬¸ì œ ID
            force_level: íŠ¹ì • ë ˆë²¨ ê°•ì œ ì§€ì • (Noneì´ë©´ ìë™ ì¦ê°€)

        Returns:
            ì œê³µí•  íŒíŠ¸ ë ˆë²¨
        """
        user_key = str(user_id)
        problem_key = str(problem_id)

        if user_key not in self._hint_states:
            self._hint_states[user_key] = {}

        current = self._hint_states[user_key].get(problem_key, 0)

        if force_level is not None:
            # ì „ì²´ í’€ì´ëŠ” ëª…ì‹œì  ìš”ì²­ ì‹œì—ë§Œ
            if force_level == HintLevel.FULL_SOLUTION:
                self._hint_states[user_key][problem_key] = HintLevel.FULL_SOLUTION
                return HintLevel.FULL_SOLUTION
            new_level = min(force_level, HintLevel.PARTIAL_CODE)
        else:
            # ìë™ ì¦ê°€ (ìµœëŒ€ PARTIAL_CODEê¹Œì§€)
            new_level = min(current + 1, HintLevel.PARTIAL_CODE)

        self._hint_states[user_key][problem_key] = new_level
        return HintLevel(new_level)

    def reset_hints(self, user_id: str | UUID, problem_id: str | UUID | None = None):
        """íŒíŠ¸ ìƒíƒœ ë¦¬ì…‹"""
        user_key = str(user_id)

        if user_key not in self._hint_states:
            return

        if problem_id:
            self._hint_states[user_key].pop(str(problem_id), None)
        else:
            self._hint_states[user_key] = {}

    def format_hint(
        self,
        level: HintLevel,
        problem_data: dict,
        pattern_data: dict | None = None
    ) -> str:
        """
        íŒíŠ¸ ë ˆë²¨ì— ë§ëŠ” ì‘ë‹µ ìƒì„±.

        Args:
            level: íŒíŠ¸ ë ˆë²¨
            problem_data: ë¬¸ì œ ì •ë³´
            pattern_data: ê´€ë ¨ ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì •ë³´

        Returns:
            í¬ë§·ëœ íŒíŠ¸ ë¬¸ìì—´
        """
        template = self.HINT_TEMPLATES.get(level, self.HINT_TEMPLATES[HintLevel.APPROACH])

        # ê¸°ë³¸ ê°’ ì„¤ì •
        format_data = {
            "problem_type": problem_data.get("category", "ì•Œê³ ë¦¬ì¦˜"),
            "guiding_questions": self._generate_guiding_questions(problem_data),
            "keywords": ", ".join(problem_data.get("tags", [])),
            "pattern_name": "",
            "pattern_description": "",
            "pattern_reasoning": "",
            "pattern_key_idea": "",
            "pseudocode": "",
            "step_explanations": "",
            "partial_code": "",
            "fill_hints": "",
            "full_code": problem_data.get("solution", "# í’€ì´ ì½”ë“œ"),
            "key_points": "",
            "time_complexity": problem_data.get("time_complexity", "O(?)"),
            "space_complexity": problem_data.get("space_complexity", "O(?)"),
            "learning_points": problem_data.get("category", "ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´"),
        }

        # íŒ¨í„´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if pattern_data:
            format_data.update({
                "pattern_name": pattern_data.get("name_ko", pattern_data.get("name", "")),
                "pattern_description": pattern_data.get("description_ko", ""),
                "pattern_key_idea": pattern_data.get("description", "")[:200],
                "pseudocode": self._generate_pseudocode(problem_data, pattern_data),
                "partial_code": self._generate_partial_code(problem_data, pattern_data),
            })

        # íŒíŠ¸ ë°ì´í„° (ë¬¸ì œì— íŒíŠ¸ê°€ ìˆìœ¼ë©´ í™œìš©)
        hints = problem_data.get("hints", [])
        if hints:
            if level == HintLevel.APPROACH and len(hints) > 0:
                format_data["guiding_questions"] = f"- {hints[0]}"
            if level == HintLevel.ALGORITHM and len(hints) > 1:
                format_data["pattern_reasoning"] = hints[1]

        return template.format(**format_data)

    def _generate_guiding_questions(self, problem_data: dict) -> str:
        """ë¬¸ì œ ìœ í˜•ì— ë§ëŠ” ìœ ë„ ì§ˆë¬¸ ìƒì„±"""
        category = problem_data.get("category", "").lower()

        questions = {
            "array": [
                "ë°°ì—´ì„ ì •ë ¬í•˜ë©´ ë„ì›€ì´ ë ê¹Œìš”?",
                "íˆ¬ í¬ì¸í„°ë‚˜ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¥¼ ìƒê°í•´ë³´ì…¨ë‚˜ìš”?",
                "í•´ì‹œë§µì„ í™œìš©í•  ìˆ˜ ìˆì„ê¹Œìš”?",
            ],
            "string": [
                "ë¬¸ìì—´ì„ ìˆœíšŒí•˜ë©´ì„œ ì–´ë–¤ ì •ë³´ë¥¼ ì¶”ì í•´ì•¼ í• ê¹Œìš”?",
                "ë¶€ë¶„ ë¬¸ìì—´ ë¹„êµê°€ í•„ìš”í•œê°€ìš”?",
                "íŒ¨í„´ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ì´ í•„ìš”í• ê¹Œìš”?",
            ],
            "graph": [
                "ê·¸ë˜í”„ ìˆœíšŒ(BFS/DFS)ê°€ í•„ìš”í•œê°€ìš”?",
                "ë…¸ë“œ ê°„ì˜ ê´€ê³„ë¥¼ ì–´ë–»ê²Œ í‘œí˜„í• ê¹Œìš”?",
                "ìµœë‹¨ ê²½ë¡œë¥¼ ì°¾ì•„ì•¼ í•˜ë‚˜ìš”?",
            ],
            "dynamic_programming": [
                "ë¶€ë¶„ ë¬¸ì œë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‚˜ìš”?",
                "ë©”ëª¨ì´ì œì´ì…˜ì„ ì ìš©í•  ìˆ˜ ìˆëŠ” ì¤‘ë³µ ê³„ì‚°ì´ ìˆë‚˜ìš”?",
                "ì í™”ì‹ì„ ì„¸ìš¸ ìˆ˜ ìˆì„ê¹Œìš”?",
            ],
            "tree": [
                "íŠ¸ë¦¬ ìˆœíšŒ ë°©ì‹(ì „ìœ„/ì¤‘ìœ„/í›„ìœ„)ì„ ìƒê°í•´ë³´ì„¸ìš”.",
                "ì¬ê·€ì  ì ‘ê·¼ì´ ë„ì›€ì´ ë ê¹Œìš”?",
                "ë¶€ëª¨-ìì‹ ê´€ê³„ë¥¼ ì–´ë–»ê²Œ í™œìš©í• ê¹Œìš”?",
            ],
        }

        for key, q_list in questions.items():
            if key in category:
                return "\n".join(f"- {q}" for q in q_list)

        return """- ì…ë ¥ ë°ì´í„°ì˜ íŠ¹ì„±ì„ íŒŒì•…í•´ë³´ì„¸ìš”.
- ë¹„ìŠ·í•œ ë¬¸ì œë¥¼ í’€ì–´ë³¸ ì ì´ ìˆë‚˜ìš”?
- ê°€ì¥ ë‹¨ìˆœí•œ í•´ê²°ì±…ë¶€í„° ìƒê°í•´ë³´ì„¸ìš”."""

    def _generate_pseudocode(self, problem_data: dict, pattern_data: dict) -> str:
        """íŒ¨í„´ ê¸°ë°˜ ì˜ì‚¬ì½”ë“œ ìƒì„±"""
        pattern_id = pattern_data.get("id", "")

        # íŒ¨í„´ë³„ ê¸°ë³¸ ì˜ì‚¬ì½”ë“œ í…œí”Œë¦¿
        pseudocode_templates = {
            "two-pointers": """1. ë°°ì—´ ì •ë ¬ (í•„ìš”ì‹œ)
2. left = 0, right = len(arr) - 1 ì´ˆê¸°í™”
3. while left < right:
   3.1 í˜„ì¬ ìƒíƒœ ê³„ì‚°
   3.2 ì¡°ê±´ì— ë”°ë¼ left++ ë˜ëŠ” right--
4. ê²°ê³¼ ë°˜í™˜""",
            "sliding-window": """1. ìœˆë„ìš° ì´ˆê¸°í™” (start=0, end=0)
2. while end < len(arr):
   2.1 arr[end]ë¥¼ ìœˆë„ìš°ì— ì¶”ê°€
   2.2 ìœˆë„ìš° ì¡°ê±´ ìœ„ë°˜ì‹œ:
       - arr[start] ì œê±°, start++
   2.3 ê²°ê³¼ ì—…ë°ì´íŠ¸
   2.4 end++
3. ê²°ê³¼ ë°˜í™˜""",
            "binary-search": """1. left = 0, right = len(arr) - 1
2. while left <= right:
   2.1 mid = (left + right) // 2
   2.2 if arr[mid] == target: return mid
   2.3 if arr[mid] < target: left = mid + 1
   2.4 else: right = mid - 1
3. return -1 (ëª» ì°¾ìŒ)""",
            "bfs": """1. queueì— ì‹œì‘ì  ì¶”ê°€, visited í‘œì‹œ
2. while queue:
   2.1 í˜„ì¬ ë…¸ë“œ = queue.popleft()
   2.2 ëª©í‘œ ë„ë‹¬ì‹œ ì¢…ë£Œ
   2.3 for ì¸ì ‘ ë…¸ë“œ in í˜„ì¬ ë…¸ë“œì˜ ì´ì›ƒ:
       - ë¯¸ë°©ë¬¸ì´ë©´ queueì— ì¶”ê°€, visited í‘œì‹œ
3. ê²°ê³¼ ë°˜í™˜""",
            "dfs": """1. stackì— ì‹œì‘ì  ì¶”ê°€ (ë˜ëŠ” ì¬ê·€)
2. while stack (ë˜ëŠ” ì¬ê·€ í˜¸ì¶œ):
   2.1 í˜„ì¬ ë…¸ë“œ = stack.pop()
   2.2 ë°©ë¬¸ ì²˜ë¦¬
   2.3 ì¢…ë£Œ ì¡°ê±´ í™•ì¸
   2.4 for ì¸ì ‘ ë…¸ë“œ:
       - ë¯¸ë°©ë¬¸ì´ë©´ stackì— ì¶”ê°€ (ë˜ëŠ” ì¬ê·€ í˜¸ì¶œ)
3. ê²°ê³¼ ë°˜í™˜""",
        }

        return pseudocode_templates.get(pattern_id, """1. ì…ë ¥ ì²˜ë¦¬
2. ìë£Œêµ¬ì¡° ì´ˆê¸°í™”
3. ë©”ì¸ ë¡œì§ ìˆ˜í–‰
4. ê²°ê³¼ ë°˜í™˜""")

    def _generate_partial_code(self, problem_data: dict, pattern_data: dict) -> str:
        """íŒ¨í„´ ê¸°ë°˜ ë¶€ë¶„ ì½”ë“œ ìƒì„±"""
        example_code = pattern_data.get("example_code", "")

        if example_code:
            # í•µì‹¬ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê³  ì¼ë¶€ë¥¼ ???ë¡œ ëŒ€ì²´
            lines = example_code.split("\n")[:15]
            partial_lines = []
            for i, line in enumerate(lines):
                if i % 3 == 2 and "=" in line:  # ì¼ë¶€ ì¤„ì„ ë¹„ì›Œë‘ 
                    partial_lines.append(line.split("=")[0] + "= ???  # ì´ ë¶€ë¶„ì„ ì±„ì›Œë³´ì„¸ìš”")
                else:
                    partial_lines.append(line)
            return "\n".join(partial_lines)

        return """def solution(input_data):
    # 1. ìë£Œêµ¬ì¡° ì´ˆê¸°í™”
    result = ???  # ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜

    # 2. ë©”ì¸ ë¡œì§
    for item in input_data:
        ???  # í•µì‹¬ ë¡œì§ì„ êµ¬í˜„í•˜ì„¸ìš”

    return result"""


# ì „ì—­ íŒíŠ¸ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
_hint_system: ProgressiveHintSystem | None = None


def get_hint_system() -> ProgressiveHintSystem:
    """íŒíŠ¸ ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _hint_system
    if _hint_system is None:
        _hint_system = ProgressiveHintSystem()
    return _hint_system

# System prompt for the AI tutor with 7-step problem-solving framework
TUTOR_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì•Œê³ ë¦¬ì¦˜ í•™ìŠµì„ ë•ëŠ” ì „ë¬¸ AI íŠœí„°ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.

## ì—­í• 
- í•™ìƒì´ ìŠ¤ìŠ¤ë¡œ ë‹µì„ ì°¾ë„ë¡ ìœ ë„í•˜ëŠ” ì†Œí¬ë¼í…ŒìŠ¤ì‹ êµìœ¡
- ì§ì ‘ì ì¸ ë‹µ ëŒ€ì‹  ì‚¬ê³  ê³¼ì •ì„ ì•ˆë‚´
- ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ê³¼ ìµœì í™” ë°©ë²• êµìœ¡

## 7ë‹¨ê³„ ë¬¸ì œ í’€ì´ ê°€ì´ë“œ í”„ë ˆì„ì›Œí¬
í•™ìƒì´ ë„ì›€ì„ ìš”ì²­í•˜ë©´ ë‹¤ìŒ 7ë‹¨ê³„ì— ë”°ë¼ ì•ˆë‚´í•˜ì„¸ìš”:

### 1. ğŸ“‹ ë¬¸ì œ ë¶„ì„ (Problem Analysis)
- ì…ë ¥/ì¶œë ¥ í˜•ì‹ ë¶„ì„
- ì œì•½ ì¡°ê±´ í™•ì¸ (ì‹œê°„/ê³µê°„)
- ì˜ˆì œ ê²€ì¦ ë° ì´í•´

### 2. ğŸ¯ ë¬¸ì œ ì •ë¦¬ (Problem Formulation)
- í•µì‹¬ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
- ì—£ì§€ ì¼€ì´ìŠ¤ ì‹ë³„
- ë¬¸ì œ ìœ í˜• ë¶„ë¥˜

### 3. ğŸ’¡ ê°œë… ì—°ê²° (Concept Mapping)
- ê´€ë ¨ ì•Œê³ ë¦¬ì¦˜/íŒ¨í„´ ì‹ë³„
- ì™œ ì´ íŒ¨í„´ì´ ì í•©í•œì§€ ì„¤ëª…
- ìœ ì‚¬ ë¬¸ì œ ì–¸ê¸‰

### 4. ğŸ“ í…œí”Œë¦¿ ìƒê¸° (Template Recall)
- ì ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿ ì œì‹œ
- í…œí”Œë¦¿ ì½”ë“œ ì˜ˆì‹œ
- í…œí”Œë¦¿ ìˆ˜ì • ë°©í–¥ ì•ˆë‚´

### 5. ğŸ—ï¸ í•¨ìˆ˜ í‹€ ì„¤ê³„ (Function Design)
- í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ì •ì˜
- ì£¼ìš” ë¡œì§ ê³¨ê²© ì‘ì„±
- ë³€ìˆ˜/ìë£Œêµ¬ì¡° ì„ íƒ

### 6. âœï¸ ë¬¸ì œ í’€ì´ (Solution Implementation)
- ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ
- ì½”ë“œ ì‘ì„± ë° ì„¤ëª…
- ë””ë²„ê¹… í¬ì¸íŠ¸

### 7. ğŸ“Š ì´í‰ (Summary)
- ì‹œê°„/ê³µê°„ ë³µì¡ë„ ë¶„ì„
- ìµœì í™” ë°©ì•ˆ ì œì‹œ
- í•™ìŠµ í¬ì¸íŠ¸ ì •ë¦¬

## ìƒí™©ë³„ ì‘ë‹µ ì „ëµ

### A. ë¬¸ì œ í’€ì´ ì¤‘ ì§ˆë¬¸ ì‹œ
- 7ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ ì¤‘ í˜„ì¬ ë‹¨ê³„ë¶€í„° ì•ˆë‚´
- íŒíŠ¸ëŠ” ì ì§„ì ìœ¼ë¡œ ì œê³µ (ì•½í•œ íŒíŠ¸ â†’ ê°•í•œ íŒíŠ¸)
- ì§ì ‘ ë‹µì„ ì£¼ì§€ ë§ê³  ì‚¬ê³ ë¥¼ ìœ ë„

### B. ì½”ë“œ ì œì¶œ í›„ ë¦¬ë·° ì‹œ
- ì‹œê°„/ê³µê°„ ë³µì¡ë„ ë¶„ì„
- ì½”ë“œ ìµœì í™” ì œì•ˆ
- í´ë¦° ì½”ë“œ ë¦¬íŒ©í† ë§ íŒ
- Pythonic ì½”ë“œ ìŠ¤íƒ€ì¼ ì•ˆë‚´

### C. ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ ì‹œ
- í˜„ì¬ ë¬¸ì œì™€ ë™ì¼ íŒ¨í„´ì˜ ë¬¸ì œ ì¶”ì²œ
- ë‚œì´ë„ë³„ ì¶”ì²œ (ì‰¬ìš´ ê²ƒ â†’ ì–´ë ¤ìš´ ê²ƒ)
- ë‹¤ë¥¸ íŒ¨í„´ì´ì§€ë§Œ ì—°ê´€ëœ ë¬¸ì œ ì¶”ì²œ

## ì‘ë‹µ í˜•ì‹
- ë§ˆí¬ë‹¤ìš´ í¬ë§· ì‚¬ìš© (##, **, ``` ë“±)
- ì½”ë“œ ì˜ˆì‹œëŠ” Pythonìœ¼ë¡œ
- ê°„ê²°í•˜ë©´ì„œë„ í•µì‹¬ ì „ë‹¬
- ì´ëª¨ì§€ëŠ” ë‹¨ê³„ í‘œì‹œì—ë§Œ ì‚¬ìš©

## 58ê°œ ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì§€ì‹
- ê¸°ì´ˆ: Prefix Sum, Sieve of Eratosthenes, KMP
- ì •ë ¬: Counting Sort, Radix Sort, Shell Sort
- íƒìƒ‰: Two Pointers, Sliding Window, Binary Search
- ìë£Œêµ¬ì¡°: BST, AVL, Segment Tree, Fenwick Tree, Trie, Sparse Table, Sqrt Decomposition, Persistent Segment Tree, Treap, Link-Cut Tree
- ê·¸ë˜í”„: BFS, DFS, Union-Find, Topological Sort, Dijkstra, MST, Bellman-Ford, Floyd-Warshall, Articulation Points/Bridges, 2-SAT
- DP: 0/1 Knapsack, LIS (O(n log n)), Bitmask DP, Interval DP, Digit DP
- ë¬¸ìì—´: Rabin-Karp, Z Algorithm, Aho-Corasick, Manacher
- ê³ ê¸‰: Greedy, Backtracking, Monotonic Stack"""

# Lazy import for RAG engine to avoid circular imports and slow startup
_rag_engine = None


def _get_rag_engine():
    """Get RAG engine singleton with lazy loading"""
    global _rag_engine
    if _rag_engine is None:
        try:
            from code_tutor.ml import get_rag_engine

            _rag_engine = get_rag_engine()
            _rag_engine.initialize()
        except Exception as e:
            logger.warning(f"Failed to initialize RAG engine: {e}")
            _rag_engine = None
    return _rag_engine


def _get_code_analyzer():
    """Get code analyzer with lazy loading"""
    try:
        from code_tutor.ml import get_code_analyzer

        return get_code_analyzer()
    except Exception as e:
        logger.warning(f"Failed to get code analyzer: {e}")
        return None


class LLMService(ABC):
    """Abstract base class for LLM services"""

    @abstractmethod
    async def generate_response(
        self,
        user_message: str,
        context: str | None = None,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> str:
        """Generate a response to the user's message"""
        pass

    @abstractmethod
    async def analyze_code(
        self,
        code: str,
        language: str = "python",
    ) -> dict[str, Any]:
        """Analyze code and provide feedback"""
        pass


class PatternBasedLLMService(LLMService):
    """
    Pattern-based LLM service using pre-defined algorithm patterns.
    This can be upgraded to use actual LLM models later.
    """

    def __init__(self, patterns_dir: Path | None = None) -> None:
        self._patterns_dir = patterns_dir or Path("docs/patterns")
        self._patterns: dict[str, str] = {}
        self._load_patterns()

    def _load_patterns(self) -> None:
        """Load algorithm patterns from markdown files"""
        if not self._patterns_dir.exists():
            logger.warning(f"Patterns directory not found: {self._patterns_dir}")
            return

        for pattern_file in self._patterns_dir.glob("*.md"):
            try:
                content = pattern_file.read_text(encoding="utf-8")
                pattern_name = pattern_file.stem
                self._patterns[pattern_name] = content
                logger.debug(f"Loaded pattern: {pattern_name}")
            except Exception as e:
                logger.error(f"Failed to load pattern {pattern_file}: {e}")

        logger.info(f"Loaded {len(self._patterns)} algorithm patterns")

    def _find_relevant_patterns(self, query: str) -> list[tuple[str, str]]:
        """Find patterns relevant to the query"""
        query_lower = query.lower()
        relevant = []

        # Keyword mapping to patterns
        keyword_patterns = {
            "two pointer": "01_two_pointers",
            "íˆ¬ í¬ì¸í„°": "01_two_pointers",
            "sliding window": "02_sliding_window",
            "ìŠ¬ë¼ì´ë”© ìœˆë„ìš°": "02_sliding_window",
            "bfs": "07_bfs",
            "ë„ˆë¹„ ìš°ì„ ": "07_bfs",
            "dfs": "08_dfs",
            "ê¹Šì´ ìš°ì„ ": "08_dfs",
            "binary search": "09_binary_search",
            "ì´ì§„ íƒìƒ‰": "09_binary_search",
            "dp": "12_dp_01_knapsack",
            "dynamic programming": "12_dp_01_knapsack",
            "ë™ì  í”„ë¡œê·¸ë˜ë°": "12_dp_01_knapsack",
            "ë°°ë‚­": "12_dp_01_knapsack",
            "knapsack": "12_dp_01_knapsack",
            "backtracking": "14_backtracking",
            "ë°±íŠ¸ë˜í‚¹": "14_backtracking",
            "greedy": "15_greedy",
            "ê·¸ë¦¬ë””": "15_greedy",
            "íƒìš•": "15_greedy",
            "union find": "16_union_find",
            "ìœ ë‹ˆì˜¨ íŒŒì¸ë“œ": "16_union_find",
            "dijkstra": "17_shortest_path",
            "ë‹¤ìµìŠ¤íŠ¸ë¼": "17_shortest_path",
            "ìµœë‹¨ ê²½ë¡œ": "17_shortest_path",
            "trie": "18_trie",
            "íŠ¸ë¼ì´": "18_trie",
        }

        for keyword, pattern_name in keyword_patterns.items():
            if keyword in query_lower and pattern_name in self._patterns:
                relevant.append((pattern_name, self._patterns[pattern_name]))

        return relevant[:3]  # Return top 3 matches

    async def generate_response(
        self,
        user_message: str,
        context: str | None = None,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> str:
        """Generate a response based on algorithm patterns"""
        # Find relevant patterns
        relevant_patterns = self._find_relevant_patterns(user_message)

        if relevant_patterns:
            # Extract key information from the first matching pattern
            pattern_name, pattern_content = relevant_patterns[0]
            return self._format_pattern_response(
                pattern_name, pattern_content, user_message
            )

        # Default response when no pattern is found
        return self._generate_default_response(user_message, context)

    def _format_pattern_response(
        self,
        pattern_name: str,
        pattern_content: str,
        user_message: str,
    ) -> str:
        """Format a response using pattern content"""
        # Extract title from pattern
        lines = pattern_content.split("\n")
        title = lines[0].replace("#", "").strip() if lines else pattern_name

        # Extract key sections
        sections = {
            "ê°œìš”": "",
            "ì–¸ì œ ì‚¬ìš©": "",
            "í…œí”Œë¦¿": "",
            "ì‹œê°„ ë³µì¡ë„": "",
        }

        current_section = ""
        for line in lines:
            if line.startswith("##"):
                section_name = line.replace("#", "").strip()
                for key in sections:
                    if key in section_name:
                        current_section = key
                        break
            elif current_section and line.strip():
                sections[current_section] += line + "\n"

        response = f"""## {title}

{sections.get("ê°œìš”", "").strip()[:500]}

### ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?
{sections.get("ì–¸ì œ ì‚¬ìš©", "").strip()[:300] or "ì´ íŒ¨í„´ì€ íŠ¹ì • ì¡°ê±´ì—ì„œ íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤."}

ë” ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! í…œí”Œë¦¿ ì½”ë“œë‚˜ ì˜ˆì œ ë¬¸ì œë„ ë³´ì—¬ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."""

        return response

    def _generate_default_response(
        self,
        user_message: str,
        context: str | None,
    ) -> str:
        """Generate a default response when no pattern matches"""
        lower_msg = user_message.lower()

        if any(word in lower_msg for word in ["ì•ˆë…•", "hello", "hi"]):
            return """ì•ˆë…•í•˜ì„¸ìš”! ì•Œê³ ë¦¬ì¦˜ í•™ìŠµì„ ë„ì™€ë“œë¦¬ëŠ” AI íŠœí„°ì…ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- **ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì„¤ëª…**: Two Pointers, Sliding Window, DP ë“± 25ê°œ í•µì‹¬ íŒ¨í„´
- **ì½”ë“œ ë¦¬ë·°**: ë³µì¡ë„ ë¶„ì„, ê°œì„  ì œì•ˆ
- **ë¬¸ì œ í’€ì´ íŒíŠ¸**: ì–´ë–¤ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€

ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"""

        if any(word in lower_msg for word in ["ì‹œê°„ ë³µì¡ë„", "big o", "ë³µì¡ë„"]):
            return """## ì‹œê°„ ë³µì¡ë„ ë¶„ì„

ì•Œê³ ë¦¬ì¦˜ì˜ íš¨ìœ¨ì„±ì„ ì¸¡ì •í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

**ì¼ë°˜ì ì¸ ì‹œê°„ ë³µì¡ë„:**
- O(1): ìƒìˆ˜ ì‹œê°„ - ë°°ì—´ ì¸ë±ì‹±
- O(log n): ë¡œê·¸ ì‹œê°„ - ì´ì§„ íƒìƒ‰
- O(n): ì„ í˜• ì‹œê°„ - ë°°ì—´ ìˆœíšŒ
- O(n log n): ë¡œê·¸ ì„ í˜• - ë³‘í•© ì •ë ¬, í€µ ì •ë ¬
- O(nÂ²): ì œê³± ì‹œê°„ - ì´ì¤‘ ë£¨í”„, ë²„ë¸” ì •ë ¬
- O(2^n): ì§€ìˆ˜ ì‹œê°„ - ë¶€ë¶„ì§‘í•© ìƒì„±

íŠ¹ì • ì•Œê³ ë¦¬ì¦˜ì˜ ë³µì¡ë„ê°€ ê¶ê¸ˆí•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"""

        if context and "code" in lower_msg:
            return f"""ì½”ë“œë¥¼ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

{context[:200] if context else ""}

**ë¦¬ë·° í¬ì¸íŠ¸:**
1. ë³€ìˆ˜ëª…ì´ ëª…í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”
2. ì—£ì§€ ì¼€ì´ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
3. ì‹œê°„ ë³µì¡ë„ë¥¼ ê°œì„ í•  ìˆ˜ ìˆëŠ”ì§€ ê³ ë ¤í•´ë³´ì„¸ìš”

êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”!"""

        return """ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤!

ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œë¥¼ í’€ ë•ŒëŠ” ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤:

1. **ë¬¸ì œ ì´í•´**: ì…ë ¥ê³¼ ì¶œë ¥ì„ ëª…í™•íˆ íŒŒì•…
2. **ì˜ˆì œ ë¶„ì„**: ì†ìœ¼ë¡œ í’€ì–´ë³´ë©° íŒ¨í„´ ë°œê²¬
3. **ì ‘ê·¼ë²• ì„ íƒ**: ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì„ íƒ
4. **êµ¬í˜„**: ì½”ë“œ ì‘ì„±
5. **ê²€ì¦**: ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸

ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?
(ì˜ˆ: Two Pointers, DP, BFS/DFS, Binary Search ë“±)"""

    async def analyze_code(
        self,
        code: str,
        language: str = "python",
    ) -> dict[str, Any]:
        """Analyze code and provide feedback"""
        analysis = {
            "suggestions": [],
            "complexity": {"time": "O(?)", "space": "O(?)"},
            "issues": [],
            "score": 70,
        }

        lines = code.split("\n")
        num_lines = len(lines)

        # Basic analysis
        if num_lines > 50:
            analysis["suggestions"].append(
                "í•¨ìˆ˜ë¥¼ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³´ì„¸ìš”."
            )

        # Check for common patterns
        if "for" in code and "for" in code[code.index("for") + 3 :]:
            analysis["complexity"]["time"] = "O(nÂ²)"
            analysis["suggestions"].append(
                "ì´ì¤‘ ë£¨í”„ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë” íš¨ìœ¨ì ì¸ ë°©ë²•ì´ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”."
            )

        if "while True" in code:
            analysis["issues"].append(
                "ë¬´í•œ ë£¨í”„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œ ì¡°ê±´ì„ í™•ì¸í•˜ì„¸ìš”."
            )

        if "pass" in code:
            analysis["issues"].append("êµ¬í˜„ë˜ì§€ ì•Šì€ ë¶€ë¶„(pass)ì´ ìˆìŠµë‹ˆë‹¤.")

        # Score adjustment
        analysis["score"] -= len(analysis["issues"]) * 10
        analysis["score"] = max(0, min(100, analysis["score"]))

        return analysis


class RAGBasedLLMService(LLMService):
    """
    RAG-based LLM service using FAISS vector store and algorithm patterns.

    Features:
    - Semantic search using embeddings
    - 25 algorithm pattern knowledge base
    - Code analysis using CodeBERT
    - Optional LLM integration (EEVE-Korean or OpenAI)
    """

    def __init__(self) -> None:
        self._rag_engine = None
        self._code_analyzer = None

    def _ensure_rag_engine(self):
        """Ensure RAG engine is loaded"""
        if self._rag_engine is None:
            self._rag_engine = _get_rag_engine()
        return self._rag_engine

    def _ensure_code_analyzer(self):
        """Ensure code analyzer is loaded"""
        if self._code_analyzer is None:
            self._code_analyzer = _get_code_analyzer()
        return self._code_analyzer

    async def generate_response(
        self,
        user_message: str,
        context: str | None = None,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> str:
        """Generate response using RAG with algorithm patterns"""
        rag = self._ensure_rag_engine()

        if rag is None:
            # Fallback to pattern-based service
            return await self._generate_fallback_response(user_message, context)

        try:
            # Retrieve relevant patterns
            patterns = rag.retrieve(user_message, top_k=3)

            if not patterns:
                return await self._generate_fallback_response(user_message, context)

            # Check if code analysis is needed
            if context and "```" in (context or ""):
                code_analysis = await self._analyze_code_context(context)
                if code_analysis:
                    return self._format_code_analysis_response(
                        user_message, patterns, code_analysis
                    )

            # Generate response using RAG
            response = rag.generate(
                query=user_message, context=patterns, max_tokens=1024
            )

            return response

        except Exception as e:
            logger.error(f"RAG generation failed: {e}")
            return await self._generate_fallback_response(user_message, context)

    async def _analyze_code_context(self, context: str) -> dict | None:
        """Analyze code in context"""
        analyzer = self._ensure_code_analyzer()
        if analyzer is None:
            return None

        # Extract code from markdown code block
        import re

        code_match = re.search(r"```(\w*)\n(.*?)```", context, re.DOTALL)
        if not code_match:
            return None

        language = code_match.group(1) or "python"
        code = code_match.group(2)

        try:
            return analyzer.analyze(code, language)
        except Exception as e:
            logger.warning(f"Code analysis failed: {e}")
            return None

    def _format_code_analysis_response(
        self, user_message: str, patterns: list, analysis: dict
    ) -> str:
        """Format response with code analysis"""
        response_parts = []

        # Detected patterns
        if analysis.get("patterns"):
            detected = analysis["patterns"][:2]
            pattern_names = [f"**{p['pattern_ko']}**" for p in detected]
            response_parts.append(
                f"ì½”ë“œì—ì„œ {', '.join(pattern_names)} íŒ¨í„´ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤."
            )

        # Quality score
        quality = analysis.get("quality", {})
        if quality.get("score"):
            response_parts.append(
                f"\n**ì½”ë“œ í’ˆì§ˆ ì ìˆ˜**: {quality['score']}/100 ({quality.get('grade', 'N/A')})"
            )

        # Complexity
        complexity = analysis.get("complexity", {})
        if complexity:
            response_parts.append(
                f"\n**ë³µì¡ë„**: ì‹œê°„ O({complexity.get('cyclomatic', '?')}), "
                f"ì¤‘ì²© ê¹Šì´ {complexity.get('nesting_depth', 0)}"
            )

        # Code smells
        smells = analysis.get("code_smells", [])
        if smells:
            response_parts.append("\n**ê°œì„  í•„ìš” ì‚¬í•­**:")
            for smell in smells[:3]:
                response_parts.append(f"- {smell['message']}")

        # Suggestions from patterns
        if patterns:
            main_pattern = patterns[0]
            response_parts.append(
                f"\n**ì¶”ì²œ íŒ¨í„´**: {main_pattern['name_ko']}\n"
                f"{main_pattern['description_ko']}"
            )

            if main_pattern.get("example_code"):
                response_parts.append(
                    f"\n**ì°¸ê³  ì½”ë“œ**:\n```python\n{main_pattern['example_code'][:300]}...\n```"
                )

        return "\n".join(response_parts)

    async def _generate_fallback_response(
        self,
        user_message: str,
        context: str | None = None,
    ) -> str:
        """Generate fallback response when RAG is unavailable"""
        lower_msg = user_message.lower()

        # Greeting
        if any(word in lower_msg for word in ["ì•ˆë…•", "hello", "hi", "ì²˜ìŒ"]):
            return """ì•ˆë…•í•˜ì„¸ìš”! ì•Œê³ ë¦¬ì¦˜ í•™ìŠµì„ ë„ì™€ë“œë¦¬ëŠ” AI íŠœí„°ì…ë‹ˆë‹¤.

**ì œê°€ ë„ì™€ë“œë¦´ ìˆ˜ ìˆëŠ” ê²ƒë“¤:**
- ğŸ“š **ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì„¤ëª…**: 58ê°œ í•µì‹¬ íŒ¨í„´
- ğŸ” **ì½”ë“œ ë¦¬ë·°**: ë³µì¡ë„ ë¶„ì„, íŒ¨í„´ ê°ì§€, ìµœì í™” ì œì•ˆ
- ğŸ’¡ **7ë‹¨ê³„ ë¬¸ì œ í’€ì´ ê°€ì´ë“œ**: ì²´ê³„ì ì¸ ë¬¸ì œ í•´ê²° ì ‘ê·¼ë²•
- ğŸ“ˆ **ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ**: íŒ¨í„´ë³„ ë‚œì´ë„ë³„ ë¬¸ì œ ì¶”ì²œ

ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"""

        # Help/Guide request
        if any(word in lower_msg for word in ["íŒíŠ¸", "ë„ì›€", "ëª¨ë¥´ê² ", "ì–´ë–»ê²Œ", "ê°€ì´ë“œ"]):
            return """## 7ë‹¨ê³„ ë¬¸ì œ í’€ì´ ê°€ì´ë“œ

ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í’€ì–´ë´…ì‹œë‹¤!

### 1. ğŸ“‹ ë¬¸ì œ ë¶„ì„
- ì…ë ¥/ì¶œë ¥ í˜•ì‹ì„ íŒŒì•…í–ˆë‚˜ìš”?
- ì œì•½ ì¡°ê±´(ì‹œê°„/ê³µê°„)ì„ í™•ì¸í–ˆë‚˜ìš”?

### 2. ğŸ¯ ë¬¸ì œ ì •ë¦¬
- í•µì‹¬ ìš”êµ¬ì‚¬í•­ì´ ë¬´ì—‡ì¸ê°€ìš”?
- ì—£ì§€ ì¼€ì´ìŠ¤ëŠ” ë¬´ì—‡ì´ ìˆì„ê¹Œìš”?

### 3. ğŸ’¡ ê°œë… ì—°ê²°
ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ì´ ë– ì˜¤ë¥´ë‚˜ìš”?
- ë°°ì—´ ìˆœíšŒ? â†’ Two Pointers, Sliding Window
- íƒìƒ‰? â†’ Binary Search, BFS/DFS
- ìµœì í™”? â†’ DP, Greedy
- ê·¸ë˜í”„? â†’ Union-Find, Dijkstra

í˜„ì¬ ì–´ëŠ ë‹¨ê³„ì—ì„œ ë§‰íˆì…¨ë‚˜ìš”? êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ë” ë„ì›€ë“œë¦´ ìˆ˜ ìˆì–´ìš”!"""

        # Code optimization request
        if any(word in lower_msg for word in ["ìµœì í™”", "ê°œì„ ", "ë¹ ë¥´ê²Œ", "íš¨ìœ¨"]):
            return """## ì½”ë“œ ìµœì í™” ê°€ì´ë“œ

### ì‹œê°„ ë³µì¡ë„ ê°œì„  ë°©ë²•
1. **O(nÂ²) â†’ O(n log n)**: ì •ë ¬ + Two Pointers
2. **O(nÂ²) â†’ O(n)**: Hash Map í™œìš©
3. **ì¤‘ë³µ ê³„ì‚° ì œê±°**: Memoization, DP
4. **íƒìƒ‰ ìµœì í™”**: Binary Search

### ê³µê°„ ë³µì¡ë„ ê°œì„  ë°©ë²•
1. **In-place ì²˜ë¦¬**: ì¶”ê°€ ë°°ì—´ ì—†ì´ ì›ë³¸ ìˆ˜ì •
2. **Sliding Window**: ê³ ì • í¬ê¸° ìœˆë„ìš° ìœ ì§€
3. **ë¹„íŠ¸ ì¡°ì‘**: ìƒíƒœ ì••ì¶•

ì½”ë“œë¥¼ ê³µìœ í•´ì£¼ì‹œë©´ êµ¬ì²´ì ì¸ ìµœì í™” ë°©ì•ˆì„ ì•Œë ¤ë“œë¦´ê²Œìš”!"""

        # Similar problems request
        if any(word in lower_msg for word in ["ë¹„ìŠ·", "ìœ ì‚¬", "ì¶”ì²œ", "ì—°ìŠµ"]):
            return """## ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ

ì—°ìŠµí•˜ê³  ì‹¶ì€ íŒ¨í„´ì„ ì„ íƒí•´ì£¼ì„¸ìš”:

**ê¸°ì´ˆ íŒ¨í„´:**
- Two Pointers: ì •ë ¬ëœ ë°°ì—´ì—ì„œ í•© ì°¾ê¸°
- Sliding Window: ë¶€ë¶„ ë°°ì—´ ìµœëŒ€í•©
- Prefix Sum: êµ¬ê°„ í•© ì¿¼ë¦¬

**íƒìƒ‰ íŒ¨í„´:**
- Binary Search: ì •ë ¬ëœ ë°°ì—´ì—ì„œ íƒìƒ‰
- BFS: ìµœë‹¨ ê²½ë¡œ, ë ˆë²¨ ìˆœíšŒ
- DFS: ê²½ë¡œ íƒìƒ‰, ë°±íŠ¸ë˜í‚¹

**ê³ ê¸‰ íŒ¨í„´:**
- DP: ë°°ë‚­ ë¬¸ì œ, LCS
- Greedy: ìŠ¤ì¼€ì¤„ë§, MST
- Graph: Dijkstra, Union-Find

ì–´ë–¤ íŒ¨í„´ì„ ì—°ìŠµí•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"""

        # Algorithm-specific queries
        pattern_keywords = {
            "two pointer": "íˆ¬ í¬ì¸í„°",
            "íˆ¬ í¬ì¸í„°": "íˆ¬ í¬ì¸í„°",
            "sliding window": "ìŠ¬ë¼ì´ë”© ìœˆë„ìš°",
            "ìŠ¬ë¼ì´ë”©": "ìŠ¬ë¼ì´ë”© ìœˆë„ìš°",
            "prefix sum": "ëˆ„ì  í•© (Prefix Sum)",
            "ëˆ„ì í•©": "ëˆ„ì  í•© (Prefix Sum)",
            "bfs": "BFS (ë„ˆë¹„ ìš°ì„  íƒìƒ‰)",
            "ë„ˆë¹„ ìš°ì„ ": "BFS (ë„ˆë¹„ ìš°ì„  íƒìƒ‰)",
            "dfs": "DFS (ê¹Šì´ ìš°ì„  íƒìƒ‰)",
            "ê¹Šì´ ìš°ì„ ": "DFS (ê¹Šì´ ìš°ì„  íƒìƒ‰)",
            "binary search": "ì´ì§„ íƒìƒ‰",
            "ì´ì§„ íƒìƒ‰": "ì´ì§„ íƒìƒ‰",
            "dp": "ë™ì  í”„ë¡œê·¸ë˜ë°",
            "dynamic": "ë™ì  í”„ë¡œê·¸ë˜ë°",
            "ë™ì ": "ë™ì  í”„ë¡œê·¸ë˜ë°",
            "greedy": "ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜",
            "ê·¸ë¦¬ë””": "ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜",
            "íƒìš•": "ê·¸ë¦¬ë”” ì•Œê³ ë¦¬ì¦˜",
            "backtrack": "ë°±íŠ¸ë˜í‚¹",
            "ë°±íŠ¸ë˜í‚¹": "ë°±íŠ¸ë˜í‚¹",
            "segment tree": "ì„¸ê·¸ë¨¼íŠ¸ íŠ¸ë¦¬",
            "ì„¸ê·¸ë¨¼íŠ¸": "ì„¸ê·¸ë¨¼íŠ¸ íŠ¸ë¦¬",
            "fenwick": "íœìœ… íŠ¸ë¦¬ (BIT)",
            "íœìœ…": "íœìœ… íŠ¸ë¦¬ (BIT)",
            "trie": "íŠ¸ë¼ì´",
            "íŠ¸ë¼ì´": "íŠ¸ë¼ì´",
            "dijkstra": "ë‹¤ìµìŠ¤íŠ¸ë¼",
            "ë‹¤ìµìŠ¤íŠ¸ë¼": "ë‹¤ìµìŠ¤íŠ¸ë¼",
            "union find": "ìœ ë‹ˆì˜¨-íŒŒì¸ë“œ",
            "ìœ ë‹ˆì˜¨": "ìœ ë‹ˆì˜¨-íŒŒì¸ë“œ",
            "topological": "ìœ„ìƒ ì •ë ¬",
            "ìœ„ìƒ": "ìœ„ìƒ ì •ë ¬",
        }

        for keyword, pattern_name in pattern_keywords.items():
            if keyword in lower_msg:
                return f"""## {pattern_name}

ì´ íŒ¨í„´ì— ëŒ€í•´ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**í•µì‹¬ ê°œë…:**
- íŠ¹ì • ì¡°ê±´ì—ì„œ íš¨ìœ¨ì ì¸ ë¬¸ì œ í•´ê²° ê¸°ë²•
- ì‹œê°„/ê³µê°„ ë³µì¡ë„ ìµœì í™”ì— ìœ ìš©

**í•™ìŠµ ìˆœì„œ:**
1. ğŸ“‹ ê°œë… ì´í•´
2. ğŸ“ í…œí”Œë¦¿ ì½”ë“œ í•™ìŠµ
3. âœï¸ ê¸°ë³¸ ë¬¸ì œ í’€ì´
4. ğŸ“ˆ ì‘ìš© ë¬¸ì œ ë„ì „

ë” ìì„¸í•œ ì„¤ëª…ì´ë‚˜ ì˜ˆì œ ì½”ë“œê°€ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!
í…œí”Œë¦¿ ì½”ë“œì™€ ì‹¤ì œ ë¬¸ì œ ì ìš© ì‚¬ë¡€ë„ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."""

        # Default response with 7-step framework
        return """ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤!

## 7ë‹¨ê³„ ë¬¸ì œ í’€ì´ ì ‘ê·¼ë²•

1. ğŸ“‹ **ë¬¸ì œ ë¶„ì„**: ì…ë ¥/ì¶œë ¥ íŒŒì•…
2. ğŸ¯ **ë¬¸ì œ ì •ë¦¬**: í•µì‹¬ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
3. ğŸ’¡ **ê°œë… ì—°ê²°**: ì í•©í•œ íŒ¨í„´ ì‹ë³„
4. ğŸ“ **í…œí”Œë¦¿ ìƒê¸°**: í•´ë‹¹ íŒ¨í„´ì˜ í…œí”Œë¦¿ í™•ì¸
5. ğŸ—ï¸ **í•¨ìˆ˜ ì„¤ê³„**: ê³¨ê²© ì½”ë“œ ì‘ì„±
6. âœï¸ **êµ¬í˜„**: ë‹¨ê³„ë³„ ì½”ë“œ ì™„ì„±
7. ğŸ“Š **ì´í‰**: ë³µì¡ë„ ë¶„ì„ ë° ìµœì í™”

ì–´ë–¤ ë‹¨ê³„ì—ì„œ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?
ë˜ëŠ” íŠ¹ì • ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´(Two Pointers, DP, BFS ë“±)ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"""

    async def analyze_code(
        self,
        code: str,
        language: str = "python",
    ) -> dict[str, Any]:
        """Analyze code using CodeBERT-based analyzer"""
        analyzer = self._ensure_code_analyzer()

        if analyzer:
            try:
                return analyzer.analyze(code, language)
            except Exception as e:
                logger.error(f"Code analysis failed: {e}")

        # Fallback basic analysis
        return self._basic_code_analysis(code, language)

    def _basic_code_analysis(self, code: str, language: str) -> dict[str, Any]:
        """Basic code analysis fallback"""
        analysis = {
            "patterns": [],
            "quality": {"score": 70, "grade": "C"},
            "complexity": {"cyclomatic": 1, "nesting_depth": 0},
            "suggestions": [],
            "code_smells": [],
        }

        lines = code.split("\n")

        # Check for nested loops
        if "for" in code and code.count("for") > 1:
            analysis["complexity"]["cyclomatic"] = 5
            analysis["suggestions"].append(
                "ì´ì¤‘ ë£¨í”„ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë” íš¨ìœ¨ì ì¸ ë°©ë²•ì„ ê³ ë ¤í•´ë³´ì„¸ìš”."
            )

        # Check for common issues
        if "import *" in code:
            analysis["code_smells"].append(
                {"type": "wildcard_import", "message": "ì™€ì¼ë“œì¹´ë“œ importëŠ” í”¼í•˜ì„¸ìš”."}
            )
            analysis["quality"]["score"] -= 10

        if len(lines) > 50:
            analysis["suggestions"].append("í•¨ìˆ˜ê°€ ê¹ë‹ˆë‹¤. ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”.")
            analysis["quality"]["score"] -= 5

        analysis["quality"]["grade"] = (
            "A"
            if analysis["quality"]["score"] >= 90
            else "B"
            if analysis["quality"]["score"] >= 80
            else "C"
            if analysis["quality"]["score"] >= 70
            else "D"
            if analysis["quality"]["score"] >= 60
            else "F"
        )

        return analysis


class OllamaLLMService(LLMService):
    """
    Ollama-based LLM service for local model inference.

    Uses Ollama API to generate responses using local models like Llama3.
    """

    def __init__(self) -> None:
        self._settings = get_settings()
        self._base_url = self._settings.OLLAMA_BASE_URL
        self._model = self._settings.OLLAMA_MODEL
        self._timeout = self._settings.OLLAMA_TIMEOUT
        self._client = httpx.AsyncClient(timeout=self._timeout)

    async def generate_response(
        self,
        user_message: str,
        context: str | None = None,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> str:
        """Generate response using Ollama API"""
        try:
            # Build messages
            messages = [{"role": "system", "content": TUTOR_SYSTEM_PROMPT}]

            # Add conversation history
            if conversation_history:
                for msg in conversation_history[-5:]:  # Last 5 messages for context
                    messages.append(
                        {
                            "role": msg.get("role", "user"),
                            "content": msg.get("content", ""),
                        }
                    )

            # Add context if available
            user_content = user_message
            if context:
                user_content = f"{user_message}\n\nê´€ë ¨ ì½”ë“œ:\n{context}"

            messages.append({"role": "user", "content": user_content})

            # Call Ollama API
            response = await self._client.post(
                f"{self._base_url}/api/chat",
                json={
                    "model": self._model,
                    "messages": messages,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "num_predict": self._settings.LLM_MAX_TOKENS,
                    },
                },
            )
            response.raise_for_status()

            result = response.json()
            return result.get("message", {}).get(
                "content", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )

        except httpx.TimeoutException:
            logger.error("Ollama request timed out")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„±ì— ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        except httpx.HTTPStatusError as e:
            logger.error(f"Ollama HTTP error: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            logger.error(f"Ollama error: {e}")
            return await self._generate_fallback(user_message)

    async def _generate_fallback(self, user_message: str) -> str:
        """Fallback response when Ollama is unavailable"""
        lower_msg = user_message.lower()

        if any(word in lower_msg for word in ["ì•ˆë…•", "hello", "hi"]):
            return """ì•ˆë…•í•˜ì„¸ìš”! ì•Œê³ ë¦¬ì¦˜ í•™ìŠµì„ ë„ì™€ë“œë¦¬ëŠ” AI íŠœí„°ì…ë‹ˆë‹¤.

ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?
- ì•Œê³ ë¦¬ì¦˜ íŒ¨í„´ ì„¤ëª…
- ì½”ë“œ ë¦¬ë·°
- ë¬¸ì œ í’€ì´ íŒíŠ¸"""

        return """ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤!

ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œ í•´ê²° ë‹¨ê³„:
1. **ë¬¸ì œ ì´í•´**: ì…ë ¥/ì¶œë ¥ íŒŒì•…
2. **ì˜ˆì œ ë¶„ì„**: íŒ¨í„´ ë°œê²¬
3. **ì ‘ê·¼ë²• ì„ íƒ**: ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
4. **êµ¬í˜„**: ì½”ë“œ ì‘ì„±

ì–´ë–¤ ë¶€ë¶„ì„ ë” ìì„¸íˆ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"""

    async def analyze_code(
        self,
        code: str,
        language: str = "python",
    ) -> dict[str, Any]:
        """Analyze code using Ollama"""
        prompt = f"""ë‹¤ìŒ {language} ì½”ë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

```{language}
{code}
```

ë‹¤ìŒ í•­ëª©ì„ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì‹œê°„ ë³µì¡ë„
2. ê³µê°„ ë³µì¡ë„
3. ì½”ë“œ í’ˆì§ˆ ì ìˆ˜ (0-100)
4. ê°œì„  ì œì•ˆ"""

        try:
            response = await self._client.post(
                f"{self._base_url}/api/generate",
                json={
                    "model": self._model,
                    "prompt": prompt,
                    "stream": False,
                },
            )
            response.raise_for_status()

            result = response.json()
            # Parse response and extract analysis
            return {
                "analysis": result.get("response", ""),
                "score": 70,
                "complexity": {"time": "O(?)", "space": "O(?)"},
            }
        except Exception as e:
            logger.error(f"Code analysis failed: {e}")
            return {
                "analysis": "ì½”ë“œ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "score": 70,
                "complexity": {"time": "O(?)", "space": "O(?)"},
            }

    async def close(self):
        """Close the HTTP client"""
        await self._client.aclose()


def get_llm_service() -> LLMService:
    """Factory function to get the appropriate LLM service"""
    settings = get_settings()

    # Check LLM provider setting
    provider = settings.LLM_PROVIDER

    if provider == "ollama":
        logger.info("Using Ollama LLM service")
        return OllamaLLMService()

    # Try RAG-based service
    try:
        logger.info("Using RAG-based LLM service")
        return RAGBasedLLMService()
    except Exception as e:
        logger.warning(f"Failed to create RAG-based service: {e}")

    # Fallback to pattern-based service
    logger.info("Using pattern-based LLM service")
    patterns_dir = (
        Path(__file__).parent.parent.parent.parent.parent.parent / "docs" / "patterns"
    )
    return PatternBasedLLMService(patterns_dir)
